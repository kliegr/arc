% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cba.R
\name{predict.CBARuleModel}
\alias{predict.CBARuleModel}
\title{Apply Rule Model}
\usage{
\method{predict}{CBARuleModel}(
  object,
  data,
  discretize = TRUE,
  outputFiringRuleIDs = FALSE,
  outputConfidenceScores = FALSE,
  confScoreType = "ordered",
  positiveClass = NULL,
  ...
)
}
\arguments{
\item{object}{a \link{CBARuleModel} class instance}

\item{data}{a data frame with data}

\item{discretize}{boolean indicating whether the passed data should be discretized
using information in the passed @cutp slot of the ruleModel argument.}

\item{outputFiringRuleIDs}{if set to TRUE, instead of predictions, the function will return one-based IDs of  rules used to classify each instance (one rule per instance).}

\item{outputConfidenceScores}{if set to TRUE, instead of predictions, the function will return confidences of the firing rule}

\item{confScoreType}{applicable only if `outputConfidenceScores=TRUE`, possible values `ordered` for confidence computed only for training instances reaching this rule, or `global` for standard rule confidence computed from the complete training data}

\item{positiveClass}{This setting is only used if `outputConfidenceScores=TRUE`. It should be used only for binary problems. In this
case, the confidence values are recalculated so that these are not confidence values of the predicted class (default behaviour of `outputConfidenceScores=TRUE`)
but rather confidence values associated with the class designated as positive}

\item{...}{other arguments (currently not used)}
}
\value{
A vector with predictions.
}
\description{
Method that matches rule model against test data.
}
\examples{
  set.seed(101)
  allData <- datasets::iris[sample(nrow(datasets::iris)),]
  trainFold <- allData[1:100,]
  testFold <- allData[101:nrow(allData),]
  #increase for more accurate results in longer time
  target_rule_count <- 1000
  classAtt <- "Species"
  rm <- cba(trainFold, classAtt, list(target_rule_count = target_rule_count))
  prediction <- predict(rm, testFold)
  acc <- CBARuleModelAccuracy(prediction, testFold[[classAtt]])
  message(acc)
  # get rules responsible for each prediction
  firingRuleIDs <- predict(rm, testFold, outputFiringRuleIDs=TRUE)
  # show rule responsible for prediction of test instance no. 28
  inspect(rm@rules[firingRuleIDs[28]])
  # get prediction confidence (three different versions)
  rm@rules[firingRuleIDs[28]]@quality$confidence
  rm@rules[firingRuleIDs[28]]@quality$orderedConf
  rm@rules[firingRuleIDs[28]]@quality$cumulativeConf
}
\seealso{
\link{cbaIris}
}
